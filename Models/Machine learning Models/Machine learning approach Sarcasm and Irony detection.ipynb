{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gt1_P6h9qNaa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sys\n",
    "import argparse\n",
    "import csv\n",
    "from scipy.sparse import *\n",
    "import pandas as pd\n",
    "import regex \n",
    "from sklearn.base import TransformerMixin\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xUEUpiZiFdWp"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9pbEdCxaSxO1"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4BsKIFFjTSdD",
    "outputId": "a01f6f1d-278a-44d4-e755-fcb2135f5a94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji==0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/1c/1f1457fe52d0b30cbeebfd578483cedb3e3619108d2d5a21380dfecf8ffd/emoji-0.6.0.tar.gz (51kB)\n",
      "\r",
      "\u001b[K     |██████▍                         | 10kB 21.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 20kB 15.1MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 30kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 40kB 12.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.6.0-cp37-none-any.whl size=49716 sha256=0e166aa950fc366fd2399964457c95f2b06823cf2cd785edca1a2228a1df05f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/2c/8b/9dcf5216ca68e14e0320e283692dce8ae321cdc01e73e17796\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyX-hIDyhZ7d",
    "outputId": "b5937b2d-0b8a-4dc4-fab3-bac83a36a252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Arabic-Stopwords\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9e/40ee9b10f98b23b32bb7ca3f229ae78ae4379ebcb03cbb7b9e7399686ad8/Arabic_Stopwords-0.3-py3-none-any.whl (353kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 7.5MB/s \n",
      "\u001b[?25hCollecting pyarabic>=0.6.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/e2/46728ec2f6fe14970de5c782346609f0636262c0941228f363710903aaa1/PyArabic-0.6.10.tar.gz (108kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 14.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyarabic\n",
      "  Building wheel for pyarabic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyarabic: filename=PyArabic-0.6.10-cp37-none-any.whl size=113324 sha256=a6a5e94e9f664015f89a3891c65d7762037cdc52d296e30c1518288b26899fce\n",
      "  Stored in directory: /root/.cache/pip/wheels/10/b8/f5/b7c1a50e6efb83544844f165a9b134afe7292585465e29b61d\n",
      "Successfully built pyarabic\n",
      "Installing collected packages: pyarabic, Arabic-Stopwords\n",
      "Successfully installed Arabic-Stopwords-0.3 pyarabic-0.6.10\n"
     ]
    }
   ],
   "source": [
    "!pip  install Arabic-Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L4JZGHD5hkGA"
   },
   "outputs": [],
   "source": [
    "import arabicstopwords.arabicstopwords as stp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gCZqqMdtTT0D"
   },
   "outputs": [],
   "source": [
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Z3QUk5jYVQlh"
   },
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oCnVjZ2HV2Kc"
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kTdWwlAoXJHz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wDfGX4OZX5S8"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WqUMjkT4bav-"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import gensim.corpora as corpora\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLE_j3AgdWu-",
    "outputId": "4b348646-fdd3-445a-ca6b-70288c43f236"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XjFymCKAdVut"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fm34AVoVFRh1",
    "outputId": "6368d5e1-02de-435a-9bf4-71cb01bfd4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0DwzoMAGIZez"
   },
   "outputs": [],
   "source": [
    "def load_w2v(filepath,binary):\n",
    "    return KeyedVectors.load_word2vec_format(filepath, binary=binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vgIly9TTSzoW"
   },
   "outputs": [],
   "source": [
    "stop_words = pd.Series(stopwords.words('arabic'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jq0f7KDzFWC8"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):  \n",
    "    # ref: https://github.com/bakrianoo/aravec\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\n",
    "              \"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n",
    "               \"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ', ' ! ']\n",
    "    \n",
    "    tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(tashkeel,\"\", text)\n",
    "    \n",
    "    longation = re.compile(r'(.)\\1+')\n",
    "    subst = r\"\\1\\1\"\n",
    "    text = re.sub(longation, subst, text)\n",
    "    \n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "    text = re.sub(r\"[a-zA-Z]\", '', text)\n",
    "    text = re.sub(r\"\\d+\", ' ', text)\n",
    "    text = re.sub(r\"\\n+\", ' ', text)\n",
    "    text = re.sub(r\"\\t+\", ' ', text)\n",
    "    text = re.sub(r\"\\r+\", ' ', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "    \n",
    "    text = text.strip()\n",
    "\n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "x2Bz6byOQIcr"
   },
   "outputs": [],
   "source": [
    "# Get the vec representation of a set of tweets based on a specified embedding (can be a word or emoji mapping)\n",
    "def get_tweets_embeddings(tweets, vec_map, embedding_dim=100, init_unk=False, variance=None, weighted_average=True):\n",
    "    # Get the variance of the embedding map\n",
    "    if init_unk and variance is None:\n",
    "        variance = embedding_variance(vec_map)\n",
    "        print(\"Vector mappings have variance \", variance)\n",
    "    # If set, calculate the tf-idf weight of each embedding, otherwise, no weighting (all weights are 1.0)\n",
    "    if weighted_average:\n",
    "        weights = get_tf_idf_weights(tweets, vec_map)\n",
    "    else:\n",
    "        weights = {k: 1.0 for k in vec_map.vocab}\n",
    "    tw_emb = np.zeros((len(tweets), embedding_dim))\n",
    "    for i, tw in enumerate(tweets):\n",
    "        total_valid = 0\n",
    "        for word in tw.split():\n",
    "            embedding_vector=None \n",
    "            if word in vec_map.wv:\n",
    "              embedding_vector = vec_map[word]\n",
    "            if embedding_vector is not None:\n",
    "                tw_emb[i] = tw_emb[i] + embedding_vector * weights[word]\n",
    "                total_valid += 1\n",
    "            elif init_unk:\n",
    "                seed(1337603)\n",
    "                tw_emb[i] = np.random.uniform(-variance, variance, size=(1, embedding_dim))\n",
    "            # else:\n",
    "            #    print(\"Not found: \", word)\n",
    "        # Get the average embedding representation for this tweet\n",
    "        tw_emb[i] /= float(max(total_valid, 1))\n",
    "    return tw_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IwhvrY-FQVEA"
   },
   "outputs": [],
   "source": [
    "# Calculate the variance of an embedding (like glove, word2vec, emoji2vec, etc)\n",
    "# Used to sample new uniform distributions of vectors in the interval [-variance, variance]\n",
    "def embedding_variance(vec_map):\n",
    "    variance = np.sum([np.var(vec) for vec in vec_map.vectors]) / len(vec_map.vectors)\n",
    "    return variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5oAYpQTxQVXL"
   },
   "outputs": [],
   "source": [
    "# Get the tf-idf weighting scheme (used to measure the contribution of a word in a tweet => weighted sum of embeddings)\n",
    "def get_tf_idf_weights(tweets, vec_map):\n",
    "    df = {}\n",
    "    for tw in tweets:\n",
    "        words = set(tw.split())\n",
    "        for word in words:\n",
    "            if word not in df:\n",
    "                df[word] = 0.0\n",
    "            df[word] += 1.0\n",
    "    idf = OrderedDict()\n",
    "    for word in vec_map.vocab:\n",
    "        n = 1.0\n",
    "        if word in df:\n",
    "            n += df[word]\n",
    "        score = math.log(len(tweets) / float(n))\n",
    "        idf[word] = score\n",
    "    return idf\n",
    "\n",
    "\n",
    "# Compute the similarity of 2 vectors, both of shape (n, )\n",
    "def cosine_similarity(u, v):\n",
    "    dot = np.dot(u, v)\n",
    "    norm_u = np.sqrt(np.sum(u ** 2))\n",
    "    norm_v = np.sqrt(np.sum(v ** 2))\n",
    "    cosine_distance = dot / (norm_u * norm_v)\n",
    "    return cosine_distance\n",
    "\n",
    "\n",
    "# Convert emojis to unicode representations by removing any variation selectors\n",
    "# Info: http://www.unicode.org/charts/PDF/UFE00.pdf\n",
    "def convert_emoji_to_unicode(emoji):\n",
    "    unicode_emoji = emoji.encode('unicode-escape')\n",
    "    find1 = unicode_emoji.find(b\"\\\\ufe0f\")\n",
    "    unicode_emoji = unicode_emoji[:find1] if find1 != -1 else unicode_emoji\n",
    "    find2 = unicode_emoji.find(b\"\\\\ufe0e\")\n",
    "    unicode_emoji = unicode_emoji[:find2] if find2 != -1 else unicode_emoji\n",
    "    return unicode_emoji\n",
    "\n",
    "\n",
    "# Performs the word analogy task: a is to b as c is to ____.\n",
    "def make_analogy(a, b, c, vec_map):\n",
    "    a = convert_emoji_to_unicode(a)\n",
    "    b = convert_emoji_to_unicode(b)\n",
    "    c = convert_emoji_to_unicode(c)\n",
    "\n",
    "    e_a, e_b, e_c = vec_map[a], vec_map[b], vec_map[c]\n",
    "\n",
    "    max_cosine_sim = -100\n",
    "    best = None\n",
    "    best_list = {}\n",
    "    for v in vec_map.keys():\n",
    "        # The best match shouldn't be one of the inputs, so pass on them.\n",
    "        if v in [a, b, c]:\n",
    "            continue\n",
    "        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)\n",
    "        cosine_sim = cosine_similarity(e_b - e_a, vec_map[v] - e_c)\n",
    "        best_list[v] = cosine_sim\n",
    "        if cosine_sim > max_cosine_sim:\n",
    "            max_cosine_sim = cosine_sim\n",
    "            best = v\n",
    "    sorted_keys = sorted(best_list, key=best_list.get, reverse=True)\n",
    "    print(\"Top 5 most similar emojis: \", [r.decode('unicode-escape') for r in sorted_keys[:5]])\n",
    "    print(str.format('{} - {} + {} = {}', a.decode('unicode-escape'), b.decode('unicode-escape'),\n",
    "                     c.decode('unicode-escape'), best.decode('unicode-escape')), \"\\n\\n\")\n",
    "\n",
    "\n",
    "# Get the Euclidean distance between two vectors\n",
    "def euclidean_distance(u_vector, v_vector):\n",
    "    distance = np.sqrt(np.sum([(u - v) ** 2 for u, v in zip(u_vector, v_vector)]))\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Given a tweet, return the scores of the most similar/dissimilar pairs of words\n",
    "def get_similarity_measures(tweet, vec_map, weighted=False, verbose=True):\n",
    "    # Filter a bit the tweet so that no punctuation and no stopwords are included\n",
    "    stopwords = data_proc.get_stopwords_list()\n",
    "    filtered_tweet = list(set([w.lower() for w in tweet.split()\n",
    "                               if w.isalnum() and w not in stopwords and w.lower() in vec_map.keys()]))\n",
    "    # Compute similarity scores between any 2 words in filtered tweet\n",
    "    similarity_scores = []\n",
    "    max_words = []\n",
    "    min_words = []\n",
    "    max_score = -100\n",
    "    min_score = 100\n",
    "    for i in range(len(filtered_tweet) - 1):\n",
    "        wi = filtered_tweet[i]\n",
    "        for j in range(i + 1, len(filtered_tweet)):\n",
    "            wj = filtered_tweet[j]\n",
    "            similarity = cosine_similarity(vec_map[wi], vec_map[wj])\n",
    "            if weighted:\n",
    "                similarity /= euclidean_distance(vec_map[wi], vec_map[wj])\n",
    "            similarity_scores.append(similarity)\n",
    "            if max_score < similarity:\n",
    "                max_score = similarity\n",
    "                max_words = [wi, wj]\n",
    "            if min_score > similarity:\n",
    "                min_score = similarity\n",
    "                min_words = [wi, wj]\n",
    "    if verbose:\n",
    "        print(\"Filtered tweet: \", filtered_tweet)\n",
    "        if max_score != -100:\n",
    "            print(\"Maximum similarity is \", max_score, \" between words \", max_words)\n",
    "        else:\n",
    "            print(\"No max! Scores are: \", similarity_scores)\n",
    "        if min_score != 100:\n",
    "            print(\"Minimum similarity is \", min_score, \" between words \", min_words)\n",
    "        else:\n",
    "            print(\"No min! Scores are: \", similarity_scores)\n",
    "    return max_score, min_score\n",
    "\n",
    "\n",
    "# Custom metric function adjusted from https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Recall metric. Only computes a batch-wise average of recall,\n",
    "    # a metric for multi-label classification of how many relevant items are selected.\n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    # Precision metric. Only computes a batch-wise average of precision,\n",
    "    # a metric for multi-label classification of how many selected items are relevant.\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision*recall) / (precision+recall))\n",
    "\n",
    "\n",
    "# This code allows you to see the mislabelled examples\n",
    "def analyse_mislabelled_examples(x_test, y_test, y_pred):\n",
    "    for i in range(len(y_test)):\n",
    "        num = np.argmax(y_pred[i])\n",
    "        if num != y_test[i]:\n",
    "            print('Expected:', y_test[i], ' but predicted ', num)\n",
    "            print(x_test[i])\n",
    "# Extract each tweet's emojis - obv. it's just a brute force solution (so, it's slow) but works in ALL cases\n",
    "def extract_emojis(tweets):\n",
    "    emojis = []\n",
    "    for tw in tweets:\n",
    "        tw_emojis = []\n",
    "        for word in tw:\n",
    "            chars = list(word)\n",
    "            for ch in chars:\n",
    "                if ch in emoji.UNICODE_EMOJI:\n",
    "                    tw_emojis.append(ch)\n",
    "        emojis.append(' '.join(tw_emojis))\n",
    "    return emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "RdDRmgcdXj1m"
   },
   "outputs": [],
   "source": [
    "# Get some idea about the max and mean length of the tweets (useful for deciding on the sequence length)\n",
    "def get_max_len_info(tweets, average=False):\n",
    "    sum_of_length = sum([len(l.split()) for l in tweets])\n",
    "    avg_tweet_len = sum_of_length / float(len(tweets))\n",
    "    print(\"Mean of train tweets: \", avg_tweet_len)\n",
    "    max_tweet_len = len(max(tweets, key=len).split())\n",
    "    print(\"Max tweet length is = \", max_tweet_len)\n",
    "    if average:\n",
    "        return avg_tweet_len\n",
    "    return max_tweet_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "JJLMqGyHXuH7"
   },
   "outputs": [],
   "source": [
    "def encode_text_as_word_indexes(train_tweets,  max_num_words=None, lower=False, char_level=False):\n",
    "    # Create the tokenizer\n",
    "    tokenizer = Tokenizer(num_words=max_num_words, filters='', lower=lower, split=\" \", char_level=char_level)\n",
    "    # Fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_tweets)\n",
    "    # Encode each example as a sequence of word indexes based on the vocabulary of the tokenizer\n",
    "    x_train = tokenizer.texts_to_sequences(train_tweets)\n",
    "   \n",
    "    return tokenizer, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Upn_TmONX1tr"
   },
   "outputs": [],
   "source": [
    "def create_bag_of_words(df):\n",
    "  wordfreq = {}\n",
    "  sentence_vectors = []\n",
    "  for comment in df:\n",
    "    corpus = nltk.sent_tokenize(comment)\n",
    "    for i in range(len(corpus )):\n",
    "      corpus [i] = corpus [i].lower()\n",
    "      corpus [i] = re.sub(r'\\W',' ',corpus [i])\n",
    "      corpus [i] = re.sub(r'\\s+',' ',corpus [i])\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        for token in tokens:\n",
    "            if token not in wordfreq.keys():\n",
    "                wordfreq[token] = 1\n",
    "            else:\n",
    "                wordfreq[token] += 1\n",
    "  \n",
    "    for sentence in corpus:\n",
    "        sentence_tokens = nltk.word_tokenize(sentence)\n",
    "        sent_vec = []\n",
    "        for token in wordfreq:\n",
    "            if token in sentence_tokens:\n",
    "                sent_vec.append(1)\n",
    "            else:\n",
    "                sent_vec.append(0)\n",
    "        sentence_vectors.append(sent_vec)\n",
    "  return np.asarray(sentence_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "xb1f75roloM1"
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    # for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "    yield(gensim.utils.simple_preprocess(str(sentences), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QtHdnB1kbPdH"
   },
   "outputs": [],
   "source": [
    "def topic_modelling(df,stop_words):\n",
    "  def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "  def remove_stopwords(texts):\n",
    "      words=[]\n",
    "      for w in texts:\n",
    "        # print(w)\n",
    "        small_list=[]\n",
    "        for www in w:\n",
    "          if www not in stop_words.tolist():\n",
    "            small_list.append(www)\n",
    "        words.append(small_list)\n",
    "      return  words\n",
    " \n",
    "  data = df.cleaned_text.values.tolist()\n",
    "  data_words = list(sent_to_words(data))\n",
    "\n",
    "  # remove stop words\n",
    "  data_words = remove_stopwords(data_words)\n",
    "  # Create Dictionary\n",
    "  id2word = corpora.Dictionary(data_words)\n",
    "  # Create Corpus\n",
    "  texts = data_words\n",
    "  # Term Document Frequency\n",
    "  corpus = [id2word.doc2bow(text) for text in texts]\n",
    "  # number of topics\n",
    "  num_topics = 1000\n",
    "  # Build LDA model\n",
    "  lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                        id2word=id2word,\n",
    "                                        num_topics=num_topics)\n",
    "  return lda_model,id2word\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ZiteNyq5ruIr"
   },
   "outputs": [],
   "source": [
    "def get_key(val,my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Lq4sJk9UFVYj"
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('')#### load train data csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LY4z4R1Mbfpe"
   },
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('')#### load test data csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "1CsBEDPlIBnK"
   },
   "outputs": [],
   "source": [
    "#### apply preprocessing as removal of URLs, stopwords, emojis, numbers, english alphabet, text normalization\n",
    "train_data['cleaned_text'] = train_data.tweet.apply(clean_text)\n",
    "test_data['cleaned_text'] = test_data.tweet.apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7iSgilB8I1w7"
   },
   "outputs": [],
   "source": [
    "# Extract just the emojis present in each tweet in each set\n",
    "x_train_emoji = extract_emojis(train_data['tweet'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "4Btei3rkb-hn"
   },
   "outputs": [],
   "source": [
    "x_test_emoji=extract_emojis(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract TF-IDF feature and Count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xhm0NLNZO_2X"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer( use_idf =True,stop_words = stop_words.tolist(), analyzer='word', lowercase=False, sublinear_tf=True)\n",
    "X_Train_tfidf = vectorizer.fit_transform(train_data['cleaned_text'].ravel())\n",
    "X_Test_tfidf = vectorizer.transform(test_data['cleaned_text'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rzrPrZLIS2FW"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(stop_words = stop_words.tolist())\n",
    "X_Train_count = count_vect.fit_transform(train_data['cleaned_text'])\n",
    "X_Test_count = count_vect.transform(test_data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Lt4MCMAfIc6l"
   },
   "outputs": [],
   "source": [
    "word2vec_map = load_w2v(\"/content/drive/MyDrive/Sentiment_Analysis_Arabic/Dataset/arabic-news.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "1CPPtHHeJE8T"
   },
   "outputs": [],
   "source": [
    "emoji2vec_map = load_w2v(\"/content/drive/MyDrive/Sentiment_Analysis_Arabic/Dataset/emoji2vec.bin\",True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tpIhTxz9TnU4"
   },
   "outputs": [],
   "source": [
    "init_unk = True\n",
    "var = None\n",
    "weighted = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply vector Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzgZX1ZTJFUv",
    "outputId": "e59f2783-01e4-44a0-fdeb-42c45d18050a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector mappings have variance  0.0033188830794231637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector mappings have variance  0.7012621721375845\n"
     ]
    }
   ],
   "source": [
    "x_train_emoji_emb = get_tweets_embeddings(x_train_emoji, emoji2vec_map, EMBEDDING_DIM,\n",
    "                                                init_unk=init_unk, variance=var, weighted_average=weighted)\n",
    "x_train_word_emb = get_tweets_embeddings(train_data['cleaned_text'], word2vec_map, EMBEDDING_DIM,\n",
    "                                               init_unk=init_unk, variance=var, weighted_average=weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rw6pJMDBcmsa",
    "outputId": "96e011de-fe6b-49dd-8400-8bb22dcf6343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector mappings have variance  0.0033188830794231637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector mappings have variance  0.7012621721375845\n"
     ]
    }
   ],
   "source": [
    "x_test_emoji_emb = get_tweets_embeddings(x_test_emoji, emoji2vec_map, EMBEDDING_DIM,\n",
    "                                                init_unk=init_unk, variance=var, weighted_average=weighted)\n",
    "x_test_word_emb = get_tweets_embeddings(test_data['cleaned_text'], word2vec_map, EMBEDDING_DIM,\n",
    "                                               init_unk=init_unk, variance=var, weighted_average=weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "ZYfwg-kmJL9I"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain features by concatenating word embeddings with all emoji embeddings\n",
    "x_train_features_concat = []\n",
    "for t, e in zip(x_train_word_emb, x_train_emoji_emb):\n",
    "    x_train_features_concat.append(np.concatenate((t, e), axis=0))\n",
    "\n",
    "\n",
    "\n",
    "# Obtain features by adding together the word embeddings with all emoji embeddings\n",
    "x_train_features_sum = []\n",
    "for t, e in zip(x_train_word_emb, x_train_emoji_emb):\n",
    "    x_train_features_sum.append(t + e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "hOMNW7A-dPdo"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Obtain features by concatenating word embeddings with all emoji embeddings\n",
    "x_test_features_concat = []\n",
    "for t, e in zip(x_test_word_emb, x_test_emoji_emb):\n",
    "    x_test_features_concat.append(np.concatenate((t, e), axis=0))\n",
    "\n",
    "\n",
    "\n",
    "# Obtain features by adding together the word embeddings with all emoji embeddings\n",
    "x_test_features_sum = []\n",
    "for t, e in zip(x_test_word_emb, x_test_emoji_emb):\n",
    "    x_test_features_sum.append(t + e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "LkGS75X9YAHf"
   },
   "outputs": [],
   "source": [
    "# Transform the output into categorical data or just keep it as it is (in a numpy array)\n",
    "train_labels_task1 = to_categorical(np.asarray(train_data['sarcasm']))\n",
    "train_labels_task2 = to_categorical(np.asarray(train_data['sentiment'].factorize()[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "UrVWLKQyda3F"
   },
   "outputs": [],
   "source": [
    "# Transform the output into categorical data or just keep it as it is (in a numpy array)\n",
    "test_labels_task1 = to_categorical(np.asarray(test_data['sarcasm']))\n",
    "test_labels_task2 = to_categorical(np.asarray(test_data['sentiment'].factorize()[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNJJQKJrZtkN"
   },
   "source": [
    "## ML Based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "J6vn6IVaZw1O"
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_statistics(y, y_pred):\n",
    "    accuracy = metrics.accuracy_score(y, y_pred)\n",
    "    precision = metrics.precision_score(y, y_pred, average='weighted')\n",
    "    recall = metrics.recall_score(y, y_pred, average='weighted')\n",
    "    f_score = metrics.f1_score(y, y_pred, average='weighted')\n",
    "    print('Accuracy: %.3f\\nPrecision: %.3f\\nRecall: %.3f\\nF_score: %.3f\\n'\n",
    "          % (accuracy, precision, recall, f_score))\n",
    "    print(metrics.classification_report(y, y_pred))\n",
    "    return accuracy, precision, recall, f_score\n",
    "\n",
    "\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20, plot_name=\"/bow_models/bow_binary_\"):\n",
    "    # Get the top most positive/negative coefficients\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    x_names = [feature_names[feature] for feature in top_coefficients]\n",
    "\n",
    "    # Plot the coefficients\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    plt.xticks(np.arange(0, 2 * top_features), x_names, rotation=30, ha='right')\n",
    "    plt.ylabel(\"Coefficient Value\")\n",
    "    plt.title(\"Visualising the top %d features taken up by an SVM model\" % top_features)\n",
    "    to_save_filename = path + \"/plots/\" + plot_name + \"top%d_coefficients.png\" % top_features\n",
    "    plt.savefig(to_save_filename)\n",
    "    print(\"Coefficients' visualisation saved to %s\\n\" % to_save_filename)\n",
    "\n",
    "def get_regularization_params(a=-1, b=1, c=3, d=1, e=5):\n",
    "    reg_range = np.outer(np.logspace(a, b, c), np.array([d, e]))\n",
    "    reg_range = reg_range.flatten()\n",
    "    return reg_range\n",
    "\n",
    "\n",
    "def grid_classifier(x_train, y_train, x_test, y_test, model, parameters,\n",
    "                    make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=parameters, verbose=0)\n",
    "    grid.fit(x_train, y_train)\n",
    "    sorted(grid.cv_results_.keys())\n",
    "    classifier = grid.best_estimator_\n",
    "    if make_feature_analysis:\n",
    "        plot_coefficients(classifier, feature_names, top_features, plot_name)\n",
    "    y_hat = classifier.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "\n",
    "# Method to print the header of the currently running model\n",
    "def print_model_title(name):\n",
    "    print(\"\\n==================================================================\")\n",
    "    print('{:>20}'.format(name))\n",
    "    print(\"==================================================================\\n\")\n",
    "\n",
    "\n",
    "def linear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "               make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Linear SVM\")\n",
    "    C_range = get_regularization_params()\n",
    "    parameters = {'C': C_range}\n",
    "    linear_svm = LinearSVC(C=1.0, class_weight=class_ratio, penalty='l2')\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, linear_svm, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def nonlinear_svm_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "                  make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Nonlinear SVM\")\n",
    "    C_range = get_regularization_params(a=-1, b=0, c=2, d=1, e=5)\n",
    "    gamma_range = get_regularization_params(a=-2, b=-1, c=2, d=1, e=5)\n",
    "    parameters = {'kernel': ['rbf'], 'C': C_range, 'gamma': gamma_range}\n",
    "    nonlinear_svm = SVC(class_weight=class_ratio)\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, nonlinear_svm, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def logistic_regression_grid(x_train, y_train, x_test, y_test, class_ratio,\n",
    "                        make_feature_analysis=False, feature_names=None, top_features=0, plot_name=\"coeff\"):\n",
    "    print_model_title(\"Logistic Regression\")\n",
    "    C_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    parameters = {'C': C_range}\n",
    "    log_regr = LogisticRegression(C=1.0, class_weight=class_ratio, penalty='l2')\n",
    "    grid_classifier(x_train, y_train, x_test, y_test, log_regr, parameters,\n",
    "                    make_feature_analysis, feature_names, top_features, plot_name)\n",
    "\n",
    "\n",
    "def linear_svm(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n",
    "    print_model_title(\"Linear SVM\")\n",
    "    svm = LinearSVC(C=0.01, class_weight=class_ratio, penalty='l2')\n",
    "    svm.fit(x_train, y_train)\n",
    "    y_hat = svm.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "\n",
    "\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, class_ratio='balanced'):\n",
    "    print_model_title(\"Logistic Regression\")\n",
    "    regr = LogisticRegression(C=0.01, class_weight=class_ratio, penalty='l2')\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_hat = regr.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)\n",
    "\n",
    "\n",
    "def feature_selection(x_train, y_train, x_test, y_test):\n",
    "    print(\"Feature selection with LinearSVC\")\n",
    "    model = LinearSVC(C=0.1, penalty='l2')\n",
    "    rfe = RFE(model, 5)\n",
    "    best_features_model = rfe.fit(x_train, y_train)\n",
    "    y_hat = best_features_model.predict(x_test)\n",
    "    print_statistics(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "n42TumIKduxi"
   },
   "outputs": [],
   "source": [
    "def get_classes_ratio_as_dict(labels):\n",
    "    ratio = Counter(labels)\n",
    "    ratio_dict = {0: float(max(ratio[0], ratio[1]) / ratio[0]), 1: float(max(ratio[0], ratio[1]) / ratio[1])}\n",
    "    print('Class ratio: ', ratio_dict)\n",
    "    return ratio_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Sentiment detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGqrB5IOKJ8O",
    "outputId": "a082fec9-e269-49e3-8a92-8f9e712d859e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.552\n",
      "Precision: 0.530\n",
      "Recall: 0.552\n",
      "F_score: 0.537\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.63      0.73      0.68      1677\n",
      "         NEU       0.36      0.27      0.31       748\n",
      "         POS       0.44      0.39      0.42       575\n",
      "\n",
      "    accuracy                           0.55      3000\n",
      "   macro avg       0.48      0.46      0.47      3000\n",
      "weighted avg       0.53      0.55      0.54      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svm(x_train_features_concat,train_data['sentiment'],x_test_features_concat,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-1NsYkLKZlJ",
    "outputId": "e2938ad3-5996-456d-e747-4b5a9398baf2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.539\n",
      "Precision: 0.517\n",
      "Recall: 0.539\n",
      "F_score: 0.524\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.62      0.72      0.67      1677\n",
      "         NEU       0.36      0.27      0.31       748\n",
      "         POS       0.41      0.35      0.38       575\n",
      "\n",
      "    accuracy                           0.54      3000\n",
      "   macro avg       0.46      0.45      0.45      3000\n",
      "weighted avg       0.52      0.54      0.52      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svm(x_train_features_sum,train_data['sentiment'],x_test_features_sum,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-01A_0wlKjes",
    "outputId": "28eded7a-29aa-462a-f1b0-b0758ff6cd59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.517\n",
      "Precision: 0.509\n",
      "Recall: 0.517\n",
      "F_score: 0.504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.63      0.67      0.65      1677\n",
      "         NEU       0.37      0.20      0.26       748\n",
      "         POS       0.35      0.49      0.40       575\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.45      0.45      0.44      3000\n",
      "weighted avg       0.51      0.52      0.50      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(x_train_features_sum,train_data['sentiment'],x_test_features_sum,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qj-2pUpxKkIX",
    "outputId": "bd6238fe-114f-4f49-9a76-105dd3fe97a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.531\n",
      "Precision: 0.515\n",
      "Recall: 0.531\n",
      "F_score: 0.515\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.63      0.70      0.66      1677\n",
      "         NEU       0.36      0.20      0.26       748\n",
      "         POS       0.37      0.48      0.42       575\n",
      "\n",
      "    accuracy                           0.53      3000\n",
      "   macro avg       0.46      0.46      0.45      3000\n",
      "weighted avg       0.52      0.53      0.51      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(x_train_features_concat,train_data['sentiment'],x_test_features_concat,test_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Sarcsam detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_WEFQAc7JxM7",
    "outputId": "2e281b90-fc52-4885-d90e-4622348e696e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio:  {0: 1.0, 1: 4.787822878228782}\n",
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.517\n",
      "Precision: 0.701\n",
      "Recall: 0.517\n",
      "F_score: 0.532\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.41      0.55      2179\n",
      "        True       0.34      0.79      0.47       821\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.59      0.60      0.51      3000\n",
      "weighted avg       0.70      0.52      0.53      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svm(x_train_features_concat,train_data['sarcasm'],x_test_features_concat,test_data['sarcasm'],get_classes_ratio_as_dict(train_data['sarcasm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tKyloleqa8Da",
    "outputId": "0c9e227a-18ee-4d5f-eb1f-f09c97469373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio:  {0: 1.0, 1: 4.787822878228782}\n",
      "\n",
      "==================================================================\n",
      "          Linear SVM\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.486\n",
      "Precision: 0.695\n",
      "Recall: 0.486\n",
      "F_score: 0.496\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.37      0.51      2179\n",
      "        True       0.32      0.81      0.46       821\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.58      0.59      0.49      3000\n",
      "weighted avg       0.69      0.49      0.50      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "linear_svm(x_train_features_sum,train_data['sarcasm'],x_test_features_sum,test_data['sarcasm'],get_classes_ratio_as_dict(train_data['sarcasm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giagye9FFKX0",
    "outputId": "1cb11742-2732-4e5a-a4e1-04511147f6df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio:  {0: 1.0, 1: 4.787822878228782}\n",
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.492\n",
      "Precision: 0.687\n",
      "Recall: 0.492\n",
      "F_score: 0.504\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.38      0.52      2179\n",
      "        True       0.32      0.78      0.46       821\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.57      0.58      0.49      3000\n",
      "weighted avg       0.69      0.49      0.50      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(x_train_features_sum,train_data['sarcasm'],x_test_features_sum,test_data['sarcasm'],get_classes_ratio_as_dict(train_data['sarcasm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkP4o-6nJ69v",
    "outputId": "30a37446-4444-4ee6-faa7-b7576a21f514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ratio:  {0: 1.0, 1: 4.787822878228782}\n",
      "\n",
      "==================================================================\n",
      " Logistic Regression\n",
      "==================================================================\n",
      "\n",
      "Accuracy: 0.519\n",
      "Precision: 0.700\n",
      "Recall: 0.519\n",
      "F_score: 0.535\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.42      0.56      2179\n",
      "        True       0.34      0.78      0.47       821\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.59      0.60      0.51      3000\n",
      "weighted avg       0.70      0.52      0.53      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression(x_train_features_concat,train_data['sarcasm'],x_test_features_concat,test_data['sarcasm'],get_classes_ratio_as_dict(train_data['sarcasm']))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Sarcasm-Detection-DL-approach.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
