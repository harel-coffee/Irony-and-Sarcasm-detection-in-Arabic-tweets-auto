{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUiwkRv-XAkW"
   },
   "source": [
    "# Download MARBERT checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5497,
     "status": "ok",
     "timestamp": 1614195455708,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "_8wBRd5zXAkX",
    "outputId": "bab12113-4288-4764-cbbc-d8ec7712954d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-24 19:37:31--  https://huggingface.co/UBC-NLP/MARBERT/resolve/main/MARBERT_pytorch_verison.tar.gz\n",
      "Resolving huggingface.co (huggingface.co)... 34.201.172.85\n",
      "Connecting to huggingface.co (huggingface.co)|34.201.172.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/UBC-NLP/MARBERT/85bfec76f38cba4bc2e6cd02a959016de37ba93de4c850a7d175811dce4e8adc [following]\n",
      "--2021-02-24 19:37:31--  https://cdn-lfs.huggingface.co/UBC-NLP/MARBERT/85bfec76f38cba4bc2e6cd02a959016de37ba93de4c850a7d175811dce4e8adc\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.84.169.48, 52.84.169.23, 52.84.169.2, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.84.169.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 607066087 (579M) [application/x-gzip]\n",
      "Saving to: ‘MARBERT_pytorch_verison.tar.gz’\n",
      "\n",
      "MARBERT_pytorch_ver 100%[===================>] 578.94M   160MB/s    in 3.6s    \n",
      "\n",
      "2021-02-24 19:37:35 (161 MB/s) - ‘MARBERT_pytorch_verison.tar.gz’ saved [607066087/607066087]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/UBC-NLP/MARBERT/resolve/main/MARBERT_pytorch_verison.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13793,
     "status": "ok",
     "timestamp": 1614195464016,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "9FYvgJevXAkY",
    "outputId": "63417f17-36ca-4a11-f43b-6a318b8b02cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARBERT_pytorch_verison/\n",
      "MARBERT_pytorch_verison/pytorch_model.bin\n",
      "MARBERT_pytorch_verison/config.json\n",
      "MARBERT_pytorch_verison/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf MARBERT_pytorch_verison.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13786,
     "status": "ok",
     "timestamp": 1614195464017,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "sUeiBs3tXAkZ",
    "outputId": "405d6cfe-7520-4fb1-dc15-980b52619bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-24 19:37:43--  https://raw.githubusercontent.com/UBC-NLP/marbert/main/examples/UBC_AJGT_final_shuffled_train.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149495 (146K) [text/plain]\n",
      "Saving to: ‘UBC_AJGT_final_shuffled_train.tsv’\n",
      "\n",
      "UBC_AJGT_final_shuf 100%[===================>] 145.99K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2021-02-24 19:37:43 (9.10 MB/s) - ‘UBC_AJGT_final_shuffled_train.tsv’ saved [149495/149495]\n",
      "\n",
      "--2021-02-24 19:37:43--  https://raw.githubusercontent.com/UBC-NLP/marbert/main/examples/UBC_AJGT_final_shuffled_test.tsv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 36901 (36K) [text/plain]\n",
      "Saving to: ‘UBC_AJGT_final_shuffled_test.tsv’\n",
      "\n",
      "UBC_AJGT_final_shuf 100%[===================>]  36.04K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2021-02-24 19:37:44 (13.4 MB/s) - ‘UBC_AJGT_final_shuffled_test.tsv’ saved [36901/36901]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/UBC-NLP/marbert/main/examples/UBC_AJGT_final_shuffled_train.tsv\n",
    "!wget https://raw.githubusercontent.com/UBC-NLP/marbert/main/examples/UBC_AJGT_final_shuffled_test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15111,
     "status": "ok",
     "timestamp": 1614195465346,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "yXM2ZsS1XAka"
   },
   "outputs": [],
   "source": [
    "!mkdir -p AJGT\n",
    "!mv UBC_AJGT_final_shuffled_train.tsv ./AJGT/UBC_AJGT_final_shuffled_train.tsv\n",
    "!mv UBC_AJGT_final_shuffled_test.tsv ./AJGT/UBC_AJGT_final_shuffled_test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25498,
     "status": "ok",
     "timestamp": 1614195475743,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "C2pkLcyfXAka",
    "outputId": "87d74ffa-f9d2-4faa-cfd3-3720c094e550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 8.7MB/s \n",
      "\u001b[?25hCollecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 13.2MB/s \n",
      "\u001b[?25hCollecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/34/b9cebec0198a40cebc0b9df8580f1f5d6d2b08edbde5a9e4300c84ba5d61/boto3-1.17.14-py2.py3-none-any.whl (130kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 51.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.7.0+cu101)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 34.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 51.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting botocore<1.21.0,>=1.20.14\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/26/239d5615b9fcad77c67d2657b62c149ebb536a77d96a1cb72b040449a2cf/botocore-1.20.14-py2.py3-none-any.whl (7.3MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3MB 50.6MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.6)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.14->boto3->pytorch_pretrained_bert) (2.8.1)\n",
      "Building wheels for collected packages: GPUtil, sacremoses\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=ae79aac7bd90a97dac6a54eafbe66ba64a9cc22418050753fc1ec7902e11d677\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=f671e6c504617f5ed238dc3a87aacb363d7bad8c8c69d967cd1a1a964a5e22a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built GPUtil sacremoses\n",
      "\u001b[31mERROR: botocore 1.20.14 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: GPUtil, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert, sacremoses, tokenizers, transformers\n",
      "Successfully installed GPUtil-1.4.0 boto3-1.17.14 botocore-1.20.14 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.4 sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install GPUtil pytorch_pretrained_bert transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95723,
     "status": "ok",
     "timestamp": 1614195545977,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "xgdLbPEQma7k",
    "outputId": "5fbb001e-9835-45bf-e080-c17be49d81f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.chdir(\"/content/drive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xBm7opGXAkb"
   },
   "source": [
    "# Fine-tuning code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8574,
     "status": "ok",
     "timestamp": 1614195557606,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "9oOXwzeXXAkb"
   },
   "outputs": [],
   "source": [
    "# (1)load libraries \n",
    "import json, sys, regex\n",
    "import torch\n",
    "import GPUtil\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig, BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
    "##----------------------------------------------------\n",
    "from transformers import *\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers import XLMRobertaModel\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import XLMRobertaForSequenceClassification, XLMRobertaTokenizer, XLMRobertaModel\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8562,
     "status": "ok",
     "timestamp": 1614195557607,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "QnNrYLjBuLFN"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3931,
     "status": "ok",
     "timestamp": 1614195561547,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "GQWKMrXPXAkc",
    "outputId": "9e3e0941-1cb7-4922-838e-f20a2b18e2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your device  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"your device \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2699,
     "status": "ok",
     "timestamp": 1614195564248,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "KKujHwr5XAkd"
   },
   "outputs": [],
   "source": [
    "def create_label2ind_file(file, label_col):\n",
    "    labels_json = {}\n",
    "\n",
    "    # load train_dev_test file\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    df.loc[df.sarcasm==False,label_col]=\"Not_Sarcasm\"\n",
    "    df.loc[df.sarcasm==True,label_col]=\"Sarcasm\"\n",
    "\n",
    "    # get labels and sort it A-Z\n",
    "\n",
    "    labels = df[label_col].unique()\n",
    "    labels.sort()\n",
    "\n",
    "    # convert labels to indexes\n",
    "\n",
    "    for idx in range(0, len(labels)):\n",
    "        labels_json[labels[idx]] = idx\n",
    "    with open(label2idx_file, 'w') as json_file:\n",
    "        json.dump(labels_json, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2696,
     "status": "ok",
     "timestamp": 1614195564249,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "szhbYX1dnbx0"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):  \n",
    "    # ref: https://github.com/bakrianoo/aravec\n",
    "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\n",
    "              \"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\n",
    "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n",
    "               \"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ', ' ! ']\n",
    "    \n",
    "    tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\n",
    "    text = re.sub(tashkeel,\"\", text)\n",
    "    \n",
    "    # longation = re.compile(r'(.)\\1+')\n",
    "    # subst = r\"\\1\\1\"\n",
    "    # text = re.sub(longation, subst, text)\n",
    "    \n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "    text = re.sub(r\"[a-zA-Z]\", '', text)\n",
    "    text = re.sub(r\"\\d+\", ' ', text)\n",
    "    text = re.sub(r\"\\n+\", ' ', text)\n",
    "    text = re.sub(r\"\\t+\", ' ', text)\n",
    "    text = re.sub(r\"\\r+\", ' ', text)\n",
    "    text = re.sub(r\"\\s+\", ' ', text)\n",
    "    text = text.replace('وو', 'و')\n",
    "    text = text.replace('يي', 'ي')\n",
    "    text = text.replace('اا', 'ا')\n",
    "    \n",
    "    for i in range(0, len(search)):\n",
    "        text = text.replace(search[i], replace[i])\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3683,
     "status": "ok",
     "timestamp": 1614195567937,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "TNZxr8m6XAkd"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def data_prepare_BERT(\n",
    "    file_path,\n",
    "    lab2ind,\n",
    "    tokenizer,\n",
    "    content_col,\n",
    "    label_col,\n",
    "    MAX_LEN,\n",
    "    ):\n",
    "\n",
    "    # Use pandas to load dataset\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df[df[content_col].notnull()]\n",
    "    df = df[df[label_col].notnull()]\n",
    "    df[content_col] = df.tweet.apply(clean_text)\n",
    "    df.loc[df.sarcasm==False,label_col]=\"Not_Sarcasm\"\n",
    "    df.loc[df.sarcasm==True,label_col]=\"Sarcasm\"\n",
    "\n",
    "\n",
    "    print ('Data size ', df.shape)\n",
    "\n",
    "    # Create sentence and label lists\n",
    "\n",
    "    sentences = df[content_col].values\n",
    "    sentences = ['[CLS] ' + sentence + ' [SEP]' for sentence in\n",
    "                 sentences]\n",
    "    print ('The first sentence:')\n",
    "    print (sentences[0])\n",
    "\n",
    "    # Create sentence and label lists\n",
    "\n",
    "    labels = df[label_col].values\n",
    "\n",
    "    # print (labels)\n",
    "\n",
    "    labels = [lab2ind[i] for i in labels]\n",
    "\n",
    "    # Import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary.\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    print ('Tokenize the first sentence:')\n",
    "    print (tokenized_texts[0])\n",
    "\n",
    "    # print(\"Label is \", labels[0])\n",
    "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in\n",
    "                 tokenized_texts]\n",
    "    print ('Index numbers of the first sentence:')\n",
    "    print (input_ids[0])\n",
    "\n",
    "    # Pad our input seqeunce to the fixed length (i.e., max_len) with index of [PAD] token\n",
    "    # ~ input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
    "    input_ids = pad_sequences(\n",
    "        input_ids,\n",
    "        maxlen=MAX_LEN + 2,\n",
    "        dtype='long',\n",
    "        truncating='post',\n",
    "        padding='post',\n",
    "        value=pad_ind,\n",
    "        )\n",
    "    print ('Index numbers of the first sentence after padding:\\n',\n",
    "           input_ids[0])\n",
    "\n",
    "    # Create attention masks\n",
    "\n",
    "    attention_masks = []\n",
    "\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i > 0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    labels = torch.tensor(labels)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "    return inputs, labels, masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1614195568817,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "wxIYQznY1r9F"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "def data_prepare_BERT_test(\n",
    "    file_path,\n",
    "    lab2ind,\n",
    "    tokenizer,\n",
    "    content_col,\n",
    "    \n",
    "    MAX_LEN,\n",
    "    ):\n",
    "\n",
    "    # Use pandas to load dataset\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    df = df[df[content_col].notnull()]\n",
    "    df[content_col] = df.tweet.apply(clean_text)\n",
    "\n",
    "\n",
    "  # df[content_col] = df.tweet.apply(clean_text)\n",
    "\n",
    "    print ('Data size ', df.shape)\n",
    "\n",
    "    # Create sentence and label lists\n",
    "\n",
    "    sentences = df[content_col].values\n",
    "    sentences = ['[CLS] ' + sentence + ' [SEP]' for sentence in\n",
    "                 sentences]\n",
    "    print ('The first sentence:')\n",
    "    print (sentences[0])\n",
    "\n",
    "    # Create sentence and label lists\n",
    "\n",
    "   \n",
    "\n",
    "    # Import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary.\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    print ('Tokenize the first sentence:')\n",
    "    print (tokenized_texts[0])\n",
    "\n",
    "    # print(\"Label is \", labels[0])\n",
    "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in\n",
    "                 tokenized_texts]\n",
    "    print ('Index numbers of the first sentence:')\n",
    "    print (input_ids[0])\n",
    "\n",
    "    # Pad our input seqeunce to the fixed length (i.e., max_len) with index of [PAD] token\n",
    "    # ~ input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
    "    input_ids = pad_sequences(\n",
    "        input_ids,\n",
    "        maxlen=MAX_LEN + 2,\n",
    "        dtype='long',\n",
    "        truncating='post',\n",
    "        padding='post',\n",
    "        value=pad_ind,\n",
    "        )\n",
    "    print ('Index numbers of the first sentence after padding:\\n',\n",
    "           input_ids[0])\n",
    "\n",
    "    # Create attention masks\n",
    "\n",
    "    attention_masks = []\n",
    "\n",
    "    # Create a mask of 1s for each token followed by 0s for padding\n",
    "\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i > 0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "    return inputs,  masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986,
     "status": "ok",
     "timestamp": 1614195576151,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "gdPCPv8VXAke"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "# def flat_accuracy(preds, labels):\n",
    "#\t  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "#\t  labels_flat = labels.flatten()\n",
    "#\t  return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "def flat_pred(preds, labels):\n",
    "\tpred_flat = np.argmax(preds, axis=1).flatten()\n",
    "\tlabels_flat = labels.flatten()\n",
    "\treturn pred_flat.tolist(), labels_flat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1783,
     "status": "ok",
     "timestamp": 1614195581126,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "5vyvc8JoXAke"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, iterator, optimizer, scheduler, criterion):\n",
    "\t\n",
    "\tmodel.train()\n",
    "\tepoch_loss = 0\n",
    "\tfor i, batch in enumerate(iterator):\n",
    "\t\t# Add batch to GPU\n",
    "\t\tbatch = tuple(t.to(device) for t in batch)\n",
    "\t\t# Unpack the inputs from our dataloader\n",
    "\t\tinput_ids, input_mask, labels = batch\n",
    "\t\toutputs = model(input_ids, input_mask, labels=labels)\n",
    "\t\tloss, logits = outputs[:2]\n",
    "\t\t# delete used variables to free GPU memory\n",
    "\t\tdel batch, input_ids, input_mask, labels\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tif torch.cuda.device_count() == 1:\n",
    "\t\t\tloss.backward()\n",
    "\t\t\tepoch_loss += loss.cpu().item()\n",
    "\t\telse:\n",
    "\t\t\tloss.sum().backward()\n",
    "\t\t\tepoch_loss += loss.sum().cpu().item()\n",
    "\t\toptimizer.step()\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore\n",
    "\t\t# optimizer.step()\n",
    "\t\tscheduler.step()\n",
    "\t# free GPU memory\n",
    "\tif device == 'cuda':\n",
    "\t\ttorch.cuda.empty_cache()\n",
    "\treturn epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2665,
     "status": "ok",
     "timestamp": 1614195589230,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "Hjwa6a3bXAkf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\tmodel.eval()\n",
    "\tepoch_loss = 0\n",
    "\tall_pred=[]\n",
    "\tall_label = []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, batch in enumerate(iterator):\n",
    "\t\t\t# Add batch to GPU\n",
    "\t\t\tbatch = tuple(t.to(device) for t in batch)\n",
    "\t\t\t# Unpack the inputs from our dataloader\n",
    "\t\t\tinput_ids, input_mask, labels = batch\n",
    "\t\t\toutputs = model(input_ids, input_mask, labels=labels)\n",
    "\t\t\tloss, logits = outputs[:2]\n",
    "\t\t\t# delete used variables to free GPU memory\n",
    "\t\t\tdel batch, input_ids, input_mask\n",
    "\t\t\tif torch.cuda.device_count() == 1:\n",
    "\t\t\t\tepoch_loss += loss.cpu().item()\n",
    "\t\t\telse:\n",
    "\t\t\t\tepoch_loss += loss.sum().cpu().item()\n",
    "\t\t\t# identify the predicted class for each example in the batch\n",
    "\t\t\tprobabilities, predicted = torch.max(logits.cpu().data, 1)\n",
    "\t\t\t# put all the true labels and predictions to two lists\n",
    "\t\t\tall_pred.extend(predicted)\n",
    "\t\t\tall_label.extend(labels.cpu())\n",
    "\taccuracy = accuracy_score(all_label, all_pred)\n",
    "\tf1score = f1_score(all_label, all_pred, average='macro') \n",
    "\trecall = recall_score(all_label, all_pred, average='macro')\n",
    "\tprecision = precision_score(all_label, all_pred, average='macro')\n",
    "\treport = classification_report(all_label, all_pred)\n",
    "\treturn (epoch_loss / len(iterator)), accuracy, f1score, recall, precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1614195599659,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "5nWmg6P-XAkf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fine_tuning(config):\n",
    "\t#---------------------------------------\n",
    "\tprint (\"[INFO] step (1) load train_test config file\")\n",
    "\t# config_file = open(config_file, 'r', encoding=\"utf8\")\n",
    "\t# config = json.load(config_file)\n",
    "\ttask_name = config[\"task_name\"]\n",
    "\tcontent_col = config[\"content_col\"]\n",
    "\tlabel_col = config[\"label_col\"]\n",
    "\ttrain_file = config[\"data_dir\"]+config[\"train_file\"]\n",
    "\tdev_file = config[\"data_dir\"]+config[\"dev_file\"]\n",
    "\tsortby = config[\"sortby\"]\n",
    "\tmax_seq_length= int(config[\"max_seq_length\"])\n",
    "\tbatch_size = int(config[\"batch_size\"])\n",
    "\tlr_var = float(config[\"lr\"])\n",
    "\tmodel_path = config['pretrained_model_path']\n",
    "\tnum_epochs = config['epochs'] # Number of training epochs (authors recommend between 2 and 4)\n",
    "\tglobal label2idx_file\n",
    "\tlabel2idx_file = config[\"data_dir\"]+config[\"task_name\"]+\"_labels-dict.json\"\n",
    "\t#-------------------------------------------------------\n",
    "\tprint (\"[INFO] step (2) convert labels2index\")\n",
    "\tcreate_label2ind_file(train_file, label_col)\n",
    "\tprint (label2idx_file)\n",
    "\t#---------------------------------------------------------\n",
    "\tprint (\"[INFO] step (3) check checkpoit directory and report file\")\n",
    "\tckpt_dir = config[\"data_dir\"]+task_name+\"_bert_ckpt/\"\n",
    "\treport = ckpt_dir+task_name+\"_report.tsv\"\n",
    "\tsorted_report = ckpt_dir+task_name+\"_report_sorted.tsv\"\n",
    "\tif not os.path.exists(ckpt_dir):\n",
    "\t\tos.mkdir(ckpt_dir)\n",
    "\t#-------------------------------------------------------\n",
    "\tprint (\"[INFO] step (4) load label to number dictionary\")\n",
    "\tlab2ind = json.load(open(label2idx_file))\n",
    "\tprint (\"[INFO] train_file\", train_file)\n",
    "\tprint (\"[INFO] dev_file\", dev_file)\n",
    "\tprint (\"[INFO] num_epochs\", num_epochs)\n",
    "\tprint (\"[INFO] model_path\", model_path)\n",
    "\tprint (\"max_seq_length\", max_seq_length, \"batch_size\", batch_size)\n",
    "\t#-------------------------------------------------------\n",
    "\tprint (\"[INFO] step (5) Use defined funtion to extract tokanize data\")\n",
    "\t# tokenizer from pre-trained BERT model\n",
    "\tprint (\"loading BERT setting\")\n",
    "\ttokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "\ttrain_inputs, train_labels, train_masks = data_prepare_BERT(train_file, lab2ind, tokenizer,content_col, label_col, max_seq_length)\n",
    "\tvalidation_inputs, validation_labels, validation_masks = data_prepare_BERT(dev_file, lab2ind, tokenizer, content_col, label_col,max_seq_length)\n",
    "\t# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
    "\tmodel = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(lab2ind))\n",
    "\t#--------------------------------------\n",
    "\tprint (\"[INFO] step (6) Create an iterator of data with torch DataLoader.\")\n",
    "#\t\t  This helps save on memory during training because, unlike a for loop,\\\n",
    "#\t\t  with an iterator the entire dataset does not need to be loaded into memory\")\n",
    "\ttrain_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "\ttrain_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\t#---------------------------\n",
    "\tvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "\tvalidation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
    "\t#------------------------------------------\n",
    "\tprint (\"[INFO] step (7) run with parallel GPUs\")\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tif torch.cuda.device_count() == 1:\n",
    "\t\t\tprint(\"Run\", \"with one GPU\")\n",
    "\t\t\tmodel = model.to(device)\n",
    "\t\telse:\n",
    "\t\t\tn_gpu = torch.cuda.device_count()\n",
    "\t\t\tprint(\"Run\", \"with\", n_gpu, \"GPUs with max 4 GPUs\")\n",
    "\t\t\tdevice_ids = GPUtil.getAvailable(limit = 4)\n",
    "\t\t\ttorch.backends.cudnn.benchmark = True\n",
    "\t\t\tmodel = model.to(device)\n",
    "\t\t\tmodel = nn.DataParallel(model, device_ids=device_ids)\n",
    "\telse:\n",
    "\t\tprint(\"Run\", \"with CPU\")\n",
    "\t\tmodel = model\n",
    "\t#---------------------------------------------------\n",
    "\tprint (\"[INFO] step (8) set Parameters, schedules, and loss function\")\n",
    "\tglobal max_grad_norm\n",
    "\tmax_grad_norm = 1.0\n",
    "\twarmup_proportion = 0.1\n",
    "\tnum_training_steps\t= len(train_dataloader) * num_epochs\n",
    "\tnum_warmup_steps = num_training_steps * warmup_proportion\n",
    "\t### In Transformers, optimizer and schedules are instantiated like this:\n",
    "\t# Note: AdamW is a class from the huggingface library\n",
    "\t# the 'W' stands for 'Weight Decay\"\n",
    "\toptimizer = AdamW(model.parameters(), lr=lr_var, correct_bias=False)\n",
    "\t# schedules\n",
    "\tscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
    "\t# We use nn.CrossEntropyLoss() as our loss function. \n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\t#---------------------------------------------------\n",
    "\tprint (\"[INFO] step (9) start fine_tuning\")\n",
    "\tfor epoch in trange(num_epochs, desc=\"Epoch\"):\n",
    "\t\ttrain_loss = train(model, train_dataloader, optimizer, scheduler, criterion)\t  \n",
    "\t\tval_loss, val_acc, val_f1, val_recall, val_precision = evaluate(model, validation_dataloader, criterion)\n",
    "# \t\tprint (train_loss, val_acc)\n",
    "\t\t# Create checkpoint at end of each epoch\n",
    "\t\tif not os.path.exists(ckpt_dir + 'model_' + str(int(epoch + 1)) + '/'): os.mkdir(ckpt_dir + 'model_' + str(int(epoch + 1)) + '/')\n",
    "\t\tmodel.save_pretrained(ckpt_dir+ 'model_' + str(int(epoch + 1)) + '/')\n",
    "\t\tepoch_eval_results = {\"epoch_num\":int(epoch + 1),\"train_loss\":train_loss,\n",
    "\t\t\t\t\t  \"val_acc\":val_acc, \"val_recall\":val_recall, \"val_precision\":val_precision, \"val_f1\":val_f1,\"lr\":lr_var }\n",
    "\t\twith open(report,\"a\") as fOut:\n",
    "\t\t\tfOut.write(json.dumps(epoch_eval_results)+\"\\n\")\n",
    "\t\t\tfOut.flush()\n",
    "\t\t#------------------------------------\n",
    "\t\treport_df = pd.read_json(report, orient='records', lines=True)\n",
    "\t\treport_df.sort_values(by=[sortby],ascending=False, inplace=True)\n",
    "\t\treport_df.to_csv(sorted_report,sep=\"\\t\",index=False)\n",
    "\treturn report_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDnDyOFHiZvk"
   },
   "source": [
    "# Run fine-tuning for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1614195605734,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "Ol6LaSAAXAki"
   },
   "outputs": [],
   "source": [
    "\n",
    "config={\"task_name\": \"Ironic_MARBERT_Task_1\", #output directory name\n",
    "             \"data_dir\": \"\", #data directory\n",
    "             \"train_file\": \"\", #train file path\n",
    "             \"dev_file\": \"\", #dev file path or test file path\n",
    "             \"pretrained_model_path\": '', #MARBERT checkpoint path\n",
    "             \"epochs\": 5, #number of epochs\n",
    "             \"content_col\": \"tweet\", #text column\n",
    "             \"label_col\": \"sarcasm\", #label column\n",
    "             \"lr\": 2e-06, #learning rate\n",
    "              \"max_seq_length\": 300, #max sequance length\n",
    "              \"batch_size\": 32, #batch shize\n",
    "              \"sortby\":\"val_acc\"} #sort results based on val_acc or val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2003544,
     "status": "ok",
     "timestamp": 1610811400112,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "jq9kOFoaXAkj",
    "outputId": "97920c22-f5b6-4368-8f30-4c92967cfb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] step (1) load train_test config file\n",
      "[INFO] step (2) convert labels2index\n",
      "/content/drive/MyDrive/Sentiment_Analysis_Arabic/Dataset/Ironic_MARBERT_Task_1_labels-dict.json\n",
      "[INFO] step (3) check checkpoit directory and report file\n",
      "[INFO] step (4) load label to number dictionary\n",
      "[INFO] train_file {'Not_Sarcasm': 0, 'Sarcasm': 1}\n",
      "[INFO] dev_file /content/drive/MyDrive/Sentiment_Analysis_Arabic/Dataset/ArSarcasm_test.csv\n",
      "[INFO] num_epochs 5\n",
      "[INFO] model_path /content/MARBERT_pytorch_verison\n",
      "max_seq_length 300 batch_size 32\n",
      "[INFO] step (5) Use defined funtion to extract tokanize data\n",
      "loading BERT setting\n",
      "Data size  (12548, 4)\n",
      "The first sentence:\n",
      "[CLS] د محمود العلايلياري ان الفريق احمد شفيق رقم مهم في المعادله السياسيه المصريه ولا يمكن اغفالههل تري ان هذا صحيحاربعه زائد واحد [SEP]\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'د', 'محمود', 'العلا', '##يلي', '##اري', 'ان', 'الفريق', 'احمد', 'شفيق', 'رقم', 'مهم', 'في', 'المعاد', '##له', 'السياسيه', 'المصريه', 'ولا', 'يمكن', 'اغف', '##اله', '##هل', 'تري', 'ان', 'هذا', 'صحيحا', '##ربع', '##ه', 'زايد', 'واحد', '[SEP]']\n",
      "Index numbers of the first sentence:\n",
      "[2, 125, 5765, 5114, 10162, 2228, 1946, 4299, 3001, 22870, 4348, 3666, 1947, 17924, 1933, 49472, 21831, 2020, 2878, 58262, 2485, 2631, 10434, 1946, 2158, 32666, 10750, 1021, 4239, 2345, 3]\n",
      "Index numbers of the first sentence after padding:\n",
      " [    2   125  5765  5114 10162  2228  1946  4299  3001 22870  4348  3666\n",
      "  1947 17924  1933 49472 21831  2020  2878 58262  2485  2631 10434  1946\n",
      "  2158 32666 10750  1021  4239  2345     3     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n",
      "Data size  (2110, 6)\n",
      "The first sentence:\n",
      "[CLS] هههههه حزب الله حطموا اسطوره الميركافا الاسرائيليه عام بينما السعوديه كانت مهتمه في بول البعير [SEP]\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'هه', '##هه', '##هه', 'حزب', 'الله', 'حطم', '##وا', 'اسطوره', 'المير', '##كا', '##فا', 'الاسراييلي', '##ه', 'عام', 'بينما', 'السعوديه', 'كانت', 'مهتمه', 'في', 'بول', 'البعير', '[SEP]']\n",
      "Index numbers of the first sentence:\n",
      "[2, 2372, 8709, 8709, 5167, 1944, 41538, 1958, 25330, 47931, 3986, 2355, 11719, 1021, 2504, 6233, 4742, 2643, 54787, 1947, 13126, 39693, 3]\n",
      "Index numbers of the first sentence after padding:\n",
      " [    2  2372  8709  8709  5167  1944 41538  1958 25330 47931  3986  2355\n",
      " 11719  1021  2504  6233  4742  2643 54787  1947 13126 39693     3     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /content/MARBERT_pytorch_verison were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/MARBERT_pytorch_verison and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\n",
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] step (6) Create an iterator of data with torch DataLoader.\n",
      "[INFO] step (7) run with parallel GPUs\n",
      "Run with one GPU\n",
      "[INFO] step (8) set Parameters, schedules, and loss function\n",
      "[INFO] step (9) start fine_tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|██        | 1/5 [06:34<26:16, 394.07s/it]\u001b[A\n",
      "Epoch:  40%|████      | 2/5 [13:08<19:42, 394.06s/it]\u001b[A\n",
      "Epoch:  60%|██████    | 3/5 [19:42<13:08, 394.09s/it]\u001b[A\n",
      "Epoch:  80%|████████  | 4/5 [26:16<06:34, 394.21s/it]\u001b[A\n",
      "Epoch: 100%|██████████| 5/5 [32:51<00:00, 394.32s/it]\n"
     ]
    }
   ],
   "source": [
    "report_df = fine_tuning(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 1972821,
     "status": "ok",
     "timestamp": 1610811400115,
     "user": {
      "displayName": "Reem Elsayed",
      "photoUrl": "",
      "userId": "13751898496823085405"
     },
     "user_tz": -120
    },
    "id": "5V9ZOdVNXAkk",
    "outputId": "99892cf5-a039-43e9-a558-9fbdc685a042"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_num</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_precision</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>0.944076</td>\n",
       "      <td>0.908273</td>\n",
       "      <td>0.892026</td>\n",
       "      <td>0.899867</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.181331</td>\n",
       "      <td>0.942180</td>\n",
       "      <td>0.915302</td>\n",
       "      <td>0.883891</td>\n",
       "      <td>0.898519</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.212130</td>\n",
       "      <td>0.929384</td>\n",
       "      <td>0.873839</td>\n",
       "      <td>0.869545</td>\n",
       "      <td>0.871671</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.256924</td>\n",
       "      <td>0.917062</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.851578</td>\n",
       "      <td>0.846057</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.388817</td>\n",
       "      <td>0.886730</td>\n",
       "      <td>0.743404</td>\n",
       "      <td>0.808139</td>\n",
       "      <td>0.769423</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_num  train_loss   val_acc  ...  val_precision    val_f1        lr\n",
       "4          5    0.165897  0.944076  ...       0.892026  0.899867  0.000002\n",
       "3          4    0.181331  0.942180  ...       0.883891  0.898519  0.000002\n",
       "2          3    0.212130  0.929384  ...       0.869545  0.871671  0.000002\n",
       "1          2    0.256924  0.917062  ...       0.851578  0.846057  0.000002\n",
       "0          1    0.388817  0.886730  ...       0.808139  0.769423  0.000002\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_extrnal_test_set():\n",
    "    lab2ind = json.load(open()) # load label2index file generated and stored in traiing pahse\n",
    "    tokenizer = BertTokenizer.from_pretrained('')#load bert tokenizer\n",
    "    max_seq_length=300\n",
    "    validation_inputs,  validation_masks = data_prepare_BERT_test('', lab2ind, tokenizer, 'tweet', max_seq_length)\n",
    "    # Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top.\n",
    "    model = BertForSequenceClassification.from_pretrained('', num_labels=len(lab2ind))\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks)\n",
    "    validation_dataloader = DataLoader(validation_data, batch_size=32)\n",
    "    ################ Evaluation and prediction#####################\n",
    "    if torch.cuda.is_available():\n",
    "\t\tif torch.cuda.device_count() == 1:\n",
    "\t\t\tprint(\"Run\", \"with one GPU\")\n",
    "\t\t\tmodel = model.to(device)\n",
    "\t\telse:\n",
    "\t\t\tn_gpu = torch.cuda.device_count()\n",
    "\t\t\tprint(\"Run\", \"with\", n_gpu, \"GPUs with max 4 GPUs\")\n",
    "\t\t\tdevice_ids = GPUtil.getAvailable(limit = 4)\n",
    "\t\t\ttorch.backends.cudnn.benchmark = True\n",
    "\t\t\tmodel = model.to(device)\n",
    "\t\t\tmodel = nn.DataParallel(model, device_ids=device_ids)\n",
    "    else:\n",
    "      print(\"Run\", \"with CPU\")\n",
    "      model = model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    with torch.no_grad():\n",
    "      for i, batch in enumerate(validation_dataloader):    \n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        # Unpack the inputs from our dataloader\n",
    "        input_ids, input_mask = batch\n",
    "        outputs = model(input_ids, input_mask)\n",
    "        logits = outputs[:2]\n",
    "        # delete used variables to free GPU memory\n",
    "        del batch, input_ids, input_mask   \n",
    "        # identify the predicted class for each example in the batch\n",
    "        probabilities, predicted = torch.max(outputs[0], 1)\n",
    "        # put all the true labels and predictions to two lists\n",
    "        all_pred.extend(predicted)\n",
    "    return all_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = predict_extrnal_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7j9Ph4i8TUZ"
   },
   "outputs": [],
   "source": [
    "def write_output_file(all_pred):\n",
    "\n",
    "    f = open(\"/content/drive/MyDrive/Sentiment_Analysis_Arabic/Dataset/Task1_MaRBERT.txt\", \"w\")\n",
    "    id=1\n",
    "    for pred in all_pred:\n",
    "\n",
    "      if pred==0:\n",
    "        f.write(\"FALSE\\n\")\n",
    "      else:\n",
    "        f.write(\"TRUE\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output_file(all_pred)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine_tune_MARBERT_from_checkpoint-task-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
